{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc53316c",
   "metadata": {
    "id": "OV5ldVqh6vSw"
   },
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4662d8ba",
   "metadata": {
    "id": "KF3yU_xQN7L3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import exposure\n",
    "from PIL import Image\n",
    "import skimage.measure\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05d32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\").iloc[:-2, :]\n",
    "val_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01daa9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAD-UFES-20/PAT_735_1391_683.png</td>\n",
       "      <td>ACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAD-UFES-20/PAT_1722_3214_672.png</td>\n",
       "      <td>ACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAD-UFES-20/PAT_730_1385_585.png</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAD-UFES-20/PAT_999_20_223.png</td>\n",
       "      <td>ACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAD-UFES-20/PAT_625_1184_994.png</td>\n",
       "      <td>SEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>PAD-UFES-20/PAT_1261_896_349.png</td>\n",
       "      <td>SEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>PAD-UFES-20/PAT_935_1781_341.png</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>PAD-UFES-20/PAT_718_1358_919.png</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>PAD-UFES-20/PAT_2153_4782_321.png</td>\n",
       "      <td>ACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>PAD-UFES-20/PAT_930_1760_560.png</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1836 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               filename diagnostic\n",
       "0      PAD-UFES-20/PAT_735_1391_683.png        ACK\n",
       "1     PAD-UFES-20/PAT_1722_3214_672.png        ACK\n",
       "2      PAD-UFES-20/PAT_730_1385_585.png        BCC\n",
       "3        PAD-UFES-20/PAT_999_20_223.png        ACK\n",
       "4      PAD-UFES-20/PAT_625_1184_994.png        SEK\n",
       "...                                 ...        ...\n",
       "1831   PAD-UFES-20/PAT_1261_896_349.png        SEK\n",
       "1832   PAD-UFES-20/PAT_935_1781_341.png        BCC\n",
       "1833   PAD-UFES-20/PAT_718_1358_919.png        BCC\n",
       "1834  PAD-UFES-20/PAT_2153_4782_321.png        ACK\n",
       "1835   PAD-UFES-20/PAT_930_1760_560.png        BCC\n",
       "\n",
       "[1836 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "286ad71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAD-UFES-20/PAT_967_1827_247.png</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAD-UFES-20/PAT_905_1721_327.png</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAD-UFES-20/PAT_1661_2956_357.png</td>\n",
       "      <td>ACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAD-UFES-20/PAT_1107_427_352.png</td>\n",
       "      <td>NEV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAD-UFES-20/PAT_2077_4463_77.png</td>\n",
       "      <td>ACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>PAD-UFES-20/PAT_1922_3848_451.png</td>\n",
       "      <td>SEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>PAD-UFES-20/PAT_1468_3656_337.png</td>\n",
       "      <td>ACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>PAD-UFES-20/PAT_406_809_581.png</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>PAD-UFES-20/PAT_1573_2497_736.png</td>\n",
       "      <td>ACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>PAD-UFES-20/PAT_14_22_850.png</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename diagnostic\n",
       "0     PAD-UFES-20/PAT_967_1827_247.png        BCC\n",
       "1     PAD-UFES-20/PAT_905_1721_327.png        BCC\n",
       "2    PAD-UFES-20/PAT_1661_2956_357.png        ACK\n",
       "3     PAD-UFES-20/PAT_1107_427_352.png        NEV\n",
       "4     PAD-UFES-20/PAT_2077_4463_77.png        ACK\n",
       "..                                 ...        ...\n",
       "455  PAD-UFES-20/PAT_1922_3848_451.png        SEK\n",
       "456  PAD-UFES-20/PAT_1468_3656_337.png        ACK\n",
       "457    PAD-UFES-20/PAT_406_809_581.png        BCC\n",
       "458  PAD-UFES-20/PAT_1573_2497_736.png        ACK\n",
       "459      PAD-UFES-20/PAT_14_22_850.png        BCC\n",
       "\n",
       "[460 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec91c5d0",
   "metadata": {
    "id": "hUGmp8EvERyY"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = train_df[\"diagnostic\"].nunique()\n",
    "TRAIN_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ae1dd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eT3O490vDn0K",
    "outputId": "909dc829-7151-4df7-a7ab-a32493f528bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1836 validated image filenames belonging to 6 classes.\n",
      "Found 460 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator (\n",
    "    rescale = 1/255.,\n",
    ")\n",
    "\n",
    "training_generator = datagen.flow_from_dataframe (\n",
    "    train_df,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"diagnostic\",\n",
    "    batch_size = BATCH_SIZE,\n",
    "    target_size = ((IMG_SIZE, IMG_SIZE)),\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe (\n",
    "    val_df,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"diagnostic\",\n",
    "    batch_size = BATCH_SIZE,\n",
    "    target_size = ((IMG_SIZE, IMG_SIZE)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbbd6232",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "8YRGjzPCSI7I",
    "outputId": "a6ca1757-9fdc-4eed-fb12-5f9685937da6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(training_generator.labels)\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "train_df.diagnostic.value_counts().sort_index().plot.bar(label=\"training\")\n",
    "val_df.diagnostic.value_counts().sort_index().plot.bar(label=\"validation\", color=\"orange\")\n",
    "plt.xlabel(\"Diagnosis\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b8828cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACK    584\n",
       "BCC    674\n",
       "MEL     42\n",
       "NEV    195\n",
       "SCC    153\n",
       "SEK    188\n",
       "Name: diagnostic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.diagnostic.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0844bb85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "N0rx_gURSNzG",
    "outputId": "bc803e95-59d0-41bb-89c9-577ae91063ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([146.,   0., 169.,   0.,  10.,   0.,  49.,   0.,  39.,  47.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(val_generator.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa08ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.523972602739726,\n",
       " 1: 0.4540059347181009,\n",
       " 2: 7.285714285714286,\n",
       " 3: 1.5692307692307692,\n",
       " 4: 2.0,\n",
       " 5: 1.627659574468085}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight \n",
    "import numpy as np\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight = 'balanced', \n",
    "    classes = np.unique(training_generator.classes), \n",
    "    y = training_generator.classes)\n",
    "class_weights = dict(zip(np.unique(training_generator.classes), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd4693fb",
   "metadata": {
    "id": "fpR8mDQxArKo"
   },
   "outputs": [],
   "source": [
    "classes = train_df[\"diagnostic\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b476fcae",
   "metadata": {
    "id": "I6aa30d3IPPP"
   },
   "source": [
    "# GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1de45ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "305dd143",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def normalize(heatmap):\n",
    "    num = heatmap - tf.reduce_min(heatmap)\n",
    "    deno = (tf.reduce_max(heatmap) - tf.reduce_min(heatmap))\n",
    "    if deno == 0:\n",
    "        return heatmap\n",
    "    heatmap = num / deno\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b4337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_gradcam_map(model, image, eps=1e-8):\n",
    "    gradModel = tf.keras.models.Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[model.get_layer(get_last_layer_name(model)).output, model.output]\n",
    "    )\n",
    "    gradModel.layers[-1].activation = tf.keras.activations.linear\n",
    "\n",
    "    with tf.GradientTape(persistent = True) as tape:\n",
    "        input_image = tf.cast(image, tf.float32)\n",
    "        convOutputs, predictions = gradModel(input_image, training=False)\n",
    "        classid = tf.argmax(predictions[0])\n",
    "        loss = predictions[:, classid]\n",
    "\n",
    "    grads = tape.gradient(loss, convOutputs)\n",
    "\n",
    "    pooled_grads = tf.reduce_mean(grads, axis = (0, 1, 2))\n",
    "\n",
    "    convOutputs = convOutputs[0]\n",
    "    heatmap = convOutputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.image.resize(heatmap[tf.newaxis, ..., tf.newaxis], [IMG_SIZE, IMG_SIZE])\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = normalize(heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "789a13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_last_layer_name(model):\n",
    "    for layer in reversed(model.layers):\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            return layer.name\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26a7b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def generate_gradcam_batch(imgs, model):\n",
    "    fused_heatmaps = []\n",
    "    for image in imgs:\n",
    "        heatmap = compute_gradcam_map(model, tf.expand_dims(image, axis = 0))\n",
    "        fused_heatmaps.append(heatmap)\n",
    "\n",
    "    return tf.convert_to_tensor(fused_heatmaps, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99069a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_heatmap(heatmap, image, alpha=0.5,colormap=cv2.COLORMAP_JET):\n",
    "    heatmap = cv2.cvtColor(cv2.applyColorMap((heatmap * 255.).astype(\"uint8\"), colormap), cv2.COLOR_BGR2RGB)\n",
    "    output = cv2.addWeighted((image * 255.).astype(\"uint8\"), alpha, heatmap, 1 - alpha, 0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e7df2",
   "metadata": {
    "id": "qrTj219eMXaS"
   },
   "source": [
    "# Train Teacher branch - DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd932d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f8aa645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DenseNet_model():\n",
    "\n",
    "    backbone_model = DenseNet121(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=tf.keras.layers.Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "    )\n",
    "\n",
    "    pooling  = tf.keras.layers.GlobalMaxPooling2D()(backbone_model.output)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(units = 1024, kernel_regularizer= tf.keras.regularizers.l2(0.0001))(pooling)\n",
    "    batch_norm = tf.keras.layers.BatchNormalization()(dense)\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batch_norm)\n",
    "    \n",
    "    classifier = tf.keras.layers.Dense(units = NUM_CLASSES, activation = 'softmax')(leaky_relu)\n",
    "    model = tf.keras.models.Model(inputs = backbone_model.input, outputs = classifier)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    # Added to improve gradcam output\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.ZeroPadding2D):\n",
    "            continue\n",
    "        layer.padding = \"same\"\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7092937",
   "metadata": {
    "id": "WkG9TRAOCXG4"
   },
   "outputs": [],
   "source": [
    "teacher_model = build_DenseNet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca5924ea",
   "metadata": {
    "id": "MyukpK2XbgLl",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "teacher_model.load_weights(\"models_gradcam/Teacher/160_1.021_0.691.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3be8f7",
   "metadata": {
    "id": "j3t3ZF_iVriQ"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c0f00",
   "metadata": {
    "id": "Y0GmonP3WkYy"
   },
   "outputs": [],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=5, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.2, \n",
    "                                            min_lr=1e-6)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('models_gradcam/Global/best_model.h5', monitor='val_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "mycallbacks = [earlystop, learning_rate_reduction,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acac0fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znpJlpJdMaf7",
    "outputId": "a8bd13ea-f10b-4838-9d84-95ec8c747c5f"
   },
   "outputs": [],
   "source": [
    "history = teacher_model.fit_generator(\n",
    "    training_generator,\n",
    "    epochs = EPOCHS,\n",
    "    validation_data = val_generator,\n",
    "    callbacks = mycallbacks,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3436d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy graph\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ce8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss graph\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = teacher_model.evaluate(val_generator)\n",
    "print(val_loss, val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9174e6",
   "metadata": {
    "id": "v5OPw6HlOh6k"
   },
   "outputs": [],
   "source": [
    "global_model.save_weights(f\"models_gradcam/Global/190_{val_loss:.3f}_{val_accuracy:.3f}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f65553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_all = []\n",
    "y_test_all = []\n",
    "labels = list(val_generator.class_indices.keys())\n",
    "print(labels)\n",
    "\n",
    "STEPS_PER_EPOCH = val_generator.samples//BATCH_SIZE\n",
    "for i in range(STEPS_PER_EPOCH):\n",
    "    print(f\"\\r{i}/{STEPS_PER_EPOCH}\", end = \"\")\n",
    "    x, y_test = val_generator.next()\n",
    "    y_pred = global_model(x, training=False)\n",
    "    for y in y_test:\n",
    "        y_test_all.append(tf.argmax(y))\n",
    "        \n",
    "    for y in y_pred:\n",
    "        y_pred_all.append(tf.argmax(y))\n",
    "        \n",
    "cm = confusion_matrix(y_test_all, y_pred_all)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38edd0e",
   "metadata": {},
   "source": [
    "# Initialize student model - MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68d9ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7c5fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Mobilenet_model():\n",
    "    backbone_model = MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=tf.keras.layers.Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "    )\n",
    "\n",
    "    pooling  = tf.keras.layers.GlobalMaxPooling2D()(backbone_model.output)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(units = 1024, kernel_regularizer= tf.keras.regularizers.l2(0.0001))(pooling)\n",
    "    batch_norm = tf.keras.layers.BatchNormalization()(dense)\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batch_norm)\n",
    "    \n",
    "    classifier = tf.keras.layers.Dense(units = NUM_CLASSES, activation = 'softmax')(leaky_relu)\n",
    "    model = tf.keras.models.Model(inputs = backbone_model.input, outputs = classifier)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    # Added to improve gradcam output\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.ZeroPadding2D):\n",
    "            continue\n",
    "        layer.padding = \"same\"\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c4a8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_loss(map1, map2):\n",
    "    return tf.reduce_mean(tf.keras.losses.mean_squared_error(map1, map2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "809967b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(tf.keras.Model):\n",
    "    def __init__(self, student):\n",
    "        super().__init__()\n",
    "#         self.teacher = teacher\n",
    "        self.student = student\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \"\"\"\n",
    "        super().compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        # Ignoring sample weights here (consider later if possible)\n",
    "        x, y, sample_weights = data        \n",
    "\n",
    "        # Forward pass of teacher\n",
    "        maps_teacher = generate_gradcam_batch(x, teacher_model) # Using the global teacher variable\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            maps_student = generate_gradcam_batch(x, self.student)\n",
    "\n",
    "            # Compute losses\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "\n",
    "            # Compute scaled distillation loss from https://arxiv.org/abs/1503.02531\n",
    "            # The magnitudes of the gradients produced by the soft targets scale\n",
    "            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.\n",
    "            distillation_loss = tf.convert_to_tensor([self.distillation_loss_fn(a, b) for (a, b) in zip(maps_teacher, maps_student)])\n",
    "\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics configured in `compile()`.\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results\n",
    "    \n",
    "#     def save_weights(filepath, **kwargs):\n",
    "#         self.student.save_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb9a7b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "student_model = build_Mobilenet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63c51e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller = Distiller(student=student_model)\n",
    "distiller.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    "    student_loss_fn=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    distillation_loss_fn=dist_loss,\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16234540",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdistiller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels_gradcam/Student/32_0.276_0.657.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:2925\u001b[0m, in \u001b[0;36mModel.load_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2920\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2921\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`load_weights` requires h5py package when loading weights \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2922\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom HDF5. Try installing h5py.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2923\u001b[0m     )\n\u001b[0;32m   2924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_graph_network \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m-> 2925\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2926\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load weights saved in HDF5 format into a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2927\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubclassed Model which has not created its variables yet. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2928\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCall the Model first, then load the weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2929\u001b[0m     )\n\u001b[0;32m   2930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_weights_created()\n\u001b[0;32m   2931\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights."
     ]
    }
   ],
   "source": [
    "distiller.load_weights(\"models_gradcam/Student/32_0.276_0.657.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48fff9c5",
   "metadata": {
    "id": "j3t3ZF_iVriQ"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf2255ed",
   "metadata": {
    "id": "Y0GmonP3WkYy"
   },
   "outputs": [],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=5, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.2, \n",
    "                                            min_lr=1e-6)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('models_gradcam/Student/{epoch:02d}_{val_student_loss:.3f}_{val_accuracy:.3f}.h5', monitor='val_accuracy', verbose=1, \n",
    "                             mode='max', save_weights_only = True)\n",
    "mycallbacks = [earlystop, learning_rate_reduction,checkpoint]\n",
    "mycallbacks = [learning_rate_reduction,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11ac08c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znpJlpJdMaf7",
    "outputId": "a8bd13ea-f10b-4838-9d84-95ec8c747c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaash\\AppData\\Local\\Temp\\ipykernel_24416\\2275153029.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = distiller.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/459 [==============================] - ETA: 0s - accuracy: 0.1580 - student_loss: 5.5047 - distillation_loss: 0.0985\n",
      "Epoch 1: saving model to models_gradcam/Student\\01_4.448_0.093.h5\n",
      "459/459 [==============================] - 964s 2s/step - accuracy: 0.1580 - student_loss: 5.4948 - distillation_loss: 0.0985 - val_accuracy: 0.0935 - val_student_loss: 4.4484 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "459/459 [==============================] - ETA: 0s - accuracy: 0.1797 - student_loss: 3.8086 - distillation_loss: 0.1023\n",
      "Epoch 2: saving model to models_gradcam/Student\\02_4.285_0.070.h5\n",
      "459/459 [==============================] - 975s 2s/step - accuracy: 0.1797 - student_loss: 3.8111 - distillation_loss: 0.1023 - val_accuracy: 0.0696 - val_student_loss: 4.2846 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "459/459 [==============================] - ETA: 0s - accuracy: 0.1944 - student_loss: 5.5045 - distillation_loss: 0.1036\n",
      "Epoch 3: saving model to models_gradcam/Student\\03_12.216_0.117.h5\n",
      "459/459 [==============================] - 1000s 2s/step - accuracy: 0.1944 - student_loss: 5.4931 - distillation_loss: 0.1036 - val_accuracy: 0.1174 - val_student_loss: 12.2165 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "459/459 [==============================] - ETA: 0s - accuracy: 0.1781 - student_loss: 6.7491 - distillation_loss: 0.0990\n",
      "Epoch 4: saving model to models_gradcam/Student\\04_4.614_0.046.h5\n",
      "459/459 [==============================] - 970s 2s/step - accuracy: 0.1781 - student_loss: 6.7695 - distillation_loss: 0.0990 - val_accuracy: 0.0457 - val_student_loss: 4.6138 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "459/459 [==============================] - ETA: 0s - accuracy: 0.1857 - student_loss: 6.5634 - distillation_loss: 0.0993\n",
      "Epoch 5: saving model to models_gradcam/Student\\05_4.140_0.033.h5\n",
      "459/459 [==============================] - 959s 2s/step - accuracy: 0.1857 - student_loss: 6.5584 - distillation_loss: 0.0993 - val_accuracy: 0.0326 - val_student_loss: 4.1396 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "459/459 [==============================] - ETA: 0s - accuracy: 0.1993 - student_loss: 4.6593 - distillation_loss: 0.0974\n",
      "Epoch 6: saving model to models_gradcam/Student\\06_8.860_0.222.h5\n",
      "459/459 [==============================] - 985s 2s/step - accuracy: 0.1993 - student_loss: 4.6602 - distillation_loss: 0.0974 - val_accuracy: 0.2217 - val_student_loss: 8.8597 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "459/459 [==============================] - ETA: 0s - accuracy: 0.1890 - student_loss: 4.2335 - distillation_loss: 0.0994\n",
      "Epoch 7: saving model to models_gradcam/Student\\07_0.329_0.302.h5\n",
      "459/459 [==============================] - 1048s 2s/step - accuracy: 0.1890 - student_loss: 4.2269 - distillation_loss: 0.0994 - val_accuracy: 0.3022 - val_student_loss: 0.3292 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "459/459 [==============================] - ETA: 0s - accuracy: 0.1808 - student_loss: 4.0877 - distillation_loss: 0.1250\n",
      "Epoch 8: saving model to models_gradcam/Student\\08_0.653_0.267.h5\n",
      "459/459 [==============================] - 1018s 2s/step - accuracy: 0.1808 - student_loss: 4.0798 - distillation_loss: 0.1249 - val_accuracy: 0.2674 - val_student_loss: 0.6534 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "459/459 [==============================] - ETA: 0s - accuracy: 0.2092 - student_loss: 3.0987 - distillation_loss: 0.1041\n",
      "Epoch 9: saving model to models_gradcam/Student\\09_0.277_0.237.h5\n",
      "459/459 [==============================] - 995s 2s/step - accuracy: 0.2092 - student_loss: 3.0941 - distillation_loss: 0.1042 - val_accuracy: 0.2370 - val_student_loss: 0.2766 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "459/459 [==============================] - ETA: 0s - accuracy: 0.1776 - student_loss: 3.2310 - distillation_loss: 0.1075\n",
      "Epoch 10: saving model to models_gradcam/Student\\10_4.053_0.302.h5\n",
      "459/459 [==============================] - 1030s 2s/step - accuracy: 0.1776 - student_loss: 3.2329 - distillation_loss: 0.1076 - val_accuracy: 0.3022 - val_student_loss: 4.0527 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "459/459 [==============================] - ETA: 0s - accuracy: 0.1786 - student_loss: 4.7288 - distillation_loss: 0.1071\n",
      "Epoch 11: saving model to models_gradcam/Student\\11_12.178_0.204.h5\n",
      "459/459 [==============================] - 1009s 2s/step - accuracy: 0.1786 - student_loss: 4.7362 - distillation_loss: 0.1070 - val_accuracy: 0.2043 - val_student_loss: 12.1776 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "459/459 [==============================] - ETA: 0s - accuracy: 0.1514 - student_loss: 5.1675 - distillation_loss: 0.1077 \n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\n",
      "Epoch 12: saving model to models_gradcam/Student\\12_8.534_0.224.h5\n",
      "459/459 [==============================] - 5152s 11s/step - accuracy: 0.1514 - student_loss: 5.1585 - distillation_loss: 0.1078 - val_accuracy: 0.2239 - val_student_loss: 8.5341 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "105/459 [=====>........................] - ETA: 12:12 - accuracy: 0.1548 - student_loss: 4.1653 - distillation_loss: 0.1088"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mdistiller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;43;03m#     steps_per_epoch=1,\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;43;03m#     validation_steps=1,\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;43;03m#     initial_epoch=32,\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmycallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:2507\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2495\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2496\u001b[0m \n\u001b[0;32m   2497\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2499\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2500\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2501\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2502\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2503\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2504\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2505\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2506\u001b[0m )\n\u001b[1;32m-> 2507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2509\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2519\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2521\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1160\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_function\u001b[39m(iterator):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;124;03m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1146\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1143\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[0;32m   1145\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1146\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1149\u001b[0m )\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1315\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1311\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1314\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1315\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2891\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2891\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3692\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3691\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 3692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    594\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1135\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1135\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mDistiller.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     36\u001b[0m x, y, sample_weights \u001b[38;5;241m=\u001b[39m data        \n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Forward pass of teacher\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m maps_teacher \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_gradcam_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Using the global teacher variable\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# Forward pass of student\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     student_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudent(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:892\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_functions_eagerly:\n\u001b[0;32m    891\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, tf_function_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;66;03m# place.\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mgenerate_gradcam_batch\u001b[1;34m(imgs, model)\u001b[0m\n\u001b[0;32m      3\u001b[0m fused_heatmaps \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m imgs:\n\u001b[1;32m----> 5\u001b[0m     heatmap \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_gradcam_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     fused_heatmaps\u001b[38;5;241m.\u001b[39mappend(heatmap)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(fused_heatmaps, tf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:892\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_functions_eagerly:\n\u001b[0;32m    891\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, tf_function_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;66;03m# place.\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mcompute_gradcam_map\u001b[1;34m(model, image, eps)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m     10\u001b[0m     input_image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(image, tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 11\u001b[0m     convOutputs, predictions \u001b[38;5;241m=\u001b[39m \u001b[43mgradModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     classid \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(predictions[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m predictions[:, classid]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    555\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[1;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\base_layer.py:1055\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;66;03m# Losses are cleared for all sublayers on the outermost `Layer.call`.\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# Losses are not cleared on inner `Layer.call`s, because sublayers can\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# be called multiple times.\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39min_call:\n\u001b[1;32m-> 1055\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clear_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m eager \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[0;32m   1059\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1060\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m   1061\u001b[0m     build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m eager,\n\u001b[0;32m   1062\u001b[0m     training\u001b[38;5;241m=\u001b[39mtraining_mode,\n\u001b[0;32m   1063\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\base_layer.py:2326\u001b[0m, in \u001b[0;36mLayer._clear_losses\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_local\u001b[38;5;241m.\u001b[39m_eager_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2326\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_layers():\n\u001b[0;32m   2327\u001b[0m         layer\u001b[38;5;241m.\u001b[39m_thread_local\u001b[38;5;241m.\u001b[39m_eager_losses \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\base_layer.py:3172\u001b[0m, in \u001b[0;36mLayer._flatten_layers\u001b[1;34m(self, recursive, include_self)\u001b[0m\n\u001b[0;32m   3171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flatten_layers\u001b[39m(\u001b[38;5;28mself\u001b[39m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, include_self\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 3172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_modules(\n\u001b[0;32m   3173\u001b[0m         recursive\u001b[38;5;241m=\u001b[39mrecursive, include_self\u001b[38;5;241m=\u001b[39minclude_self\n\u001b[0;32m   3174\u001b[0m     ):\n\u001b[0;32m   3175\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, Layer):\n\u001b[0;32m   3176\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\base_layer.py:3204\u001b[0m, in \u001b[0;36mLayer._flatten_modules\u001b[1;34m(self, recursive, include_self)\u001b[0m\n\u001b[0;32m   3201\u001b[0m seen_object_ids\u001b[38;5;241m.\u001b[39madd(trackable_id)\n\u001b[0;32m   3203\u001b[0m \u001b[38;5;66;03m# Metrics are not considered part of the Layer's topology.\u001b[39;00m\n\u001b[1;32m-> 3204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrackable_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModule\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   3205\u001b[0m     trackable_obj, metrics_mod\u001b[38;5;241m.\u001b[39mMetric\n\u001b[0;32m   3206\u001b[0m ):\n\u001b[0;32m   3207\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m trackable_obj\n\u001b[0;32m   3208\u001b[0m     \u001b[38;5;66;03m# Introspect recursively through sublayers.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = distiller.fit_generator(\n",
    "    training_generator,\n",
    "#     steps_per_epoch=1,\n",
    "#     validation_steps=1,\n",
    "    epochs = EPOCHS,\n",
    "#     initial_epoch=32,\n",
    "    validation_data = val_generator,\n",
    "    callbacks = mycallbacks,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy graph\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e36e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss graph\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a697d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = distiller.evaluate(val_generator)\n",
    "print(val_loss, val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6051ecae",
   "metadata": {
    "id": "kMx_VLppw7NX"
   },
   "source": [
    "# Visualize and Save attention maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d387fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e230f",
   "metadata": {
    "id": "7V-LNe7BNrpu"
   },
   "outputs": [],
   "source": [
    "images, labels = training_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69229c3b",
   "metadata": {
    "id": "DeVkIQ-1Nw4F"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "heatmaps = generate_gradcam_batch(images, distiller.student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd21b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaid_images = [overlay_heatmap(hmap.numpy(), img, alpha=0.8) for (hmap, img) in zip(heatmaps, images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8747e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True labels: \", tf.argmax(labels, axis = 1).numpy())\n",
    "print(\"Predictions: \", tf.argmax(teacher_model(images), axis=1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad83329",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack(heatmaps), cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack(overlaid_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1af915",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"MIPS_teacher\"\n",
    "!mkdir \"$OUTPUT_FOLDER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c1462",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_START = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bcafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir \"$OUTPUT_FOLDER/images\"\n",
    "for img_id, (img, label) in enumerate(zip(images, labels)):\n",
    "    plt.imsave(f\"{OUTPUT_FOLDER}/images/{img_id + IMAGE_START}_{tf.argmax(label)}.jpg\", img, cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45145034",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir \"$OUTPUT_FOLDER/gradcams\"\n",
    "for img_id, (img, label) in enumerate(zip(heatmaps, labels)):\n",
    "    plt.imsave(f\"{OUTPUT_FOLDER}/gradcams/{img_id + IMAGE_START}_{tf.argmax(label)}.jpg\", img, cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a8cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir \"$OUTPUT_FOLDER/overlaid\"\n",
    "for img_id, (img, label) in enumerate(zip(overlaid_images, labels)):\n",
    "    plt.imsave(f\"{OUTPUT_FOLDER}/overlaid/{img_id + IMAGE_START}_{tf.argmax(label)}.jpg\", img, cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7635484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
